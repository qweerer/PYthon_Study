# WEEK01-01切片

#python/pytorch

```python
import torch
import numpy as np
```

## view(): 浅拷贝,而且大多数切割都是属于浅拷贝

```python
t = torch.tensor([[1,2,3,4,5,6],
				  [4,5,6,7,8,9]])
t1 = t[1, 1:4]
```

```txt
tensor([[1, 2, 3, 4, 5, 6],
		[4, 5, 6, 7, 8, 9]])
tensor([5, 6, 7])
```

```python
t1[2] = 100
print(t1)
print('#'*20)
print(t)
```

```txt
tensor([ 5, 6, 100])
#################### 
tensor([[ 1, 2, 3, 4, 5], 
		[ 4, 5, 6, 100, 8]])
```

### 注意pandas也有这个特性

```python
import pandas as pd
date = pd.DataFrame([[1,3,4,5],
					[2,4,5,6]])
date2 = date.loc[:, 1:4]
date2
```

![result](./0image/Pasted%20image%2020210728110500.png)

```python
date2.loc[1,1] = 100
print(date2)
print('#'*20)
print(date)
```

```txt
     1  2  3
0    3  4  5
1  100  5  6
####################
   0    1  2  3
0  1    3  4  5
1  2  100  5  6

/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: [https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy)
  iloc._setitem_with_indexer(indexer, value)
/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: [https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy)
  """Entry point for launching an IPython kernel.
```

### torch.chunk(等分) 与 torch.split(规则切分)

```python
torch.chunk(目标元素, 需要几等分, dim = 按照哪一个维度)
torch.split(目标元素, 切分规则, 按照哪一个维度)
```

- 规定每一个元素的长度

```python
torch.split(t, 2, 1)
```

    tensor([[1, 2], [4, 5]]), 
	tensor([[3, 4],[6, 7]]), 
	tensor([[5, 6],[8, 9]]))

- 可以看到第一个元素有4列,但而二个元素就只有2列了

```python
torch.split(t, 4, 1)
```
```txt
tensor([[1, 2, 3, 4],
        [4, 5, 6, 7]]), 
tensor([[5, 6],
        [8, 9]]))
```

- 按照2:4来分, 元素相加必须与其长度相同

```python
torch.split(t, [2,4], 1)
```
```txt
tensor([[1, 2],
        [4, 5]]), 
tensor([[3, 4, 5, 6],
        [6, 7, 8, 9]]))
```

## 合并

### torch.cat([t1,t2], 按照哪个维度拼接)

```python
t1 = torch.ones(2,3)
t2 = torch.zeros(2,3)
t1
t2
```

```txt
tensor([[1., 1., 1.],
        [1., 1., 1.]])
tensor([[0., 0., 0.],
        [0., 0., 0.]])
```

```python
torch.cat([t1, t2], 1)
```
```txt
    tensor([[1., 1., 1., 0., 0., 0.],
            [1., 1., 1., 0., 0., 0.]])
```

### torch.stack([A, B]) 堆叠为更高一层的张量

```python
torch.stack([t1, t2])
```
```txt
    tensor([[[1., 1., 1.],
             [1., 1., 1.]],
    
            [[0., 0., 0.],
             [0., 0., 0.]]])
```

## torch.squeeze() 与 torch.unsqueeze()

删除不必要的维度 与 进行升维

```python
t = torch.tensor([[1,2,3]])
t
```
```txt
tensor([[1, 2, 3]])
```

```python
t = torch.squeeze(t)
t
```
```txt
    tensor([1, 2, 3])
```

后面使用函数，t的值不变, size=[3]

dim=1时, 在size=1的地方插入一个维度，现在size=[3, 1]
```python
torch.unsqueeze(t, dim=1)
```
```txt
    tensor([[1],
            [2],
            [3]])
```

```python
torch.unsqueeze(t, dim=-1)
```
```txt
    tensor([[1],
            [2],
            [3]])
```

```python
torch.unsqueeze(t, dim=0)
```

    tensor([[1, 2, 3]])

```python
torch.unsqueeze(t, dim=-2)
```

    tensor([[1, 2, 3]])
